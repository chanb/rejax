{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "\n",
    "from functools import partial\n",
    "from rejax import get_algo\n",
    "from rejax.evaluate import evaluate, EvalState\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import _pickle as pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"lqr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./configs/custom/{}.yaml\".format(env_name)\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f.read())\n",
    "\n",
    "algo_name = \"ppo\"\n",
    "config = config[algo_name]\n",
    "num_seeds = 5\n",
    "\n",
    "num_files = 1\n",
    "starting_seed_id = 0\n",
    "\n",
    "max_steps_in_episode = 200\n",
    "\n",
    "if env_name == \"cartpole\":\n",
    "    from gymnax.environments.classic_control.cartpole import EnvParams, CartPole\n",
    "    env = CartPole()\n",
    "\n",
    "    def sample_env_params(key):\n",
    "        return {\n",
    "            \"gravity\": jax.random.uniform(key, shape=(num_seeds,)) * 10.0\n",
    "        }\n",
    "\n",
    "    def apply_env_params(algo_cls, env_params):\n",
    "        return algo_cls.create(\n",
    "            **config,\n",
    "            env_params=EnvParams(\n",
    "                gravity=env_params[\"gravity\"],\n",
    "                max_steps_in_episode=max_steps_in_episode,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "elif env_name == \"lqr\":\n",
    "    from rejax.envs.lqr import EnvParams, DiscreteTimeLQR\n",
    "\n",
    "    dim_x = 2\n",
    "    dim_u = 2\n",
    "    horizon = 200\n",
    "    env = DiscreteTimeLQR(dim_x, dim_u)\n",
    "\n",
    "    def sample_env_params(key):\n",
    "        return {\n",
    "            \"A\": jax.random.normal(\n",
    "                jax.random.fold_in(key, 0),\n",
    "                shape=(num_seeds, dim_x, dim_x),\n",
    "            ),\n",
    "            \"B\": jax.random.normal(\n",
    "                jax.random.fold_in(key, 1),\n",
    "                shape=(num_seeds, dim_u, dim_u),\n",
    "            ),\n",
    "            \"Q\": jnp.concatenate([jnp.diag(\n",
    "                1.0 - jax.random.uniform(\n",
    "                    jax.random.fold_in(jax.random.fold_in(key, 2), seed),\n",
    "                    shape=(dim_x),\n",
    "                )\n",
    "            )[None] for seed in range(num_seeds)], axis=0),\n",
    "            \"R\": jnp.concatenate([jnp.diag(\n",
    "                1.0 - jax.random.uniform(\n",
    "                    jax.random.fold_in(jax.random.fold_in(key, 3), seed),\n",
    "                    shape=(dim_u),\n",
    "                )\n",
    "            )[None] for seed in range(num_seeds)], axis=0),\n",
    "        }\n",
    "\n",
    "    def apply_env_params(algo_cls, env_params):\n",
    "        return algo_cls.create(\n",
    "            **config,\n",
    "            env_params=EnvParams(\n",
    "                A=env_params[\"A\"],\n",
    "                B=env_params[\"B\"],\n",
    "                Q=env_params[\"Q\"],\n",
    "                R=env_params[\"R\"],\n",
    "                max_steps_in_episode=max_steps_in_episode,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "config[\"env\"] = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cace57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_i in tqdm(range(num_files)):\n",
    "    seed_id = starting_seed_id + file_i\n",
    "\n",
    "    key = jax.random.PRNGKey(seed_id)\n",
    "    keys = jax.random.split(key, num_seeds)\n",
    "\n",
    "    env_params = sample_env_params(key)\n",
    "\n",
    "    algo_cls = get_algo(algo_name)\n",
    "    algo = jax.vmap(\n",
    "        apply_env_params,\n",
    "        in_axes=(None, 0),\n",
    "    )(\n",
    "        algo_cls,\n",
    "        env_params,\n",
    "    )\n",
    "\n",
    "    def eval_callback(algo, ts, rng):\n",
    "        act = algo.make_act(ts)\n",
    "        return evaluate(act, rng, env, algo.env_params, 50, max_steps_in_episode)\n",
    "\n",
    "    def get_returns(algo, ts, rng):\n",
    "        eval_info = eval_callback(algo, ts, rng)\n",
    "        return eval_info.length, eval_info.return_\n",
    "\n",
    "    algo = algo.replace(\n",
    "        eval_callback=get_returns\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    vmap_train = jax.jit(jax.vmap(algo_cls.train, in_axes=(0, 0)))\n",
    "    ts, (_, returns) = vmap_train(algo, keys)\n",
    "    returns.block_until_ready()\n",
    "\n",
    "    # Get expert actions\n",
    "    def get_expert_actions(ts, num_steps):\n",
    "        act = algo.make_act(ts)\n",
    "        def step(step_i: int, state: EvalState):\n",
    "            rng, rng_act, rng_step = jax.random.split(state.rng, 3)\n",
    "            action = act(state.trajectory[\"obss\"][step_i], rng_act)\n",
    "\n",
    "            state = EvalState(\n",
    "                rng,\n",
    "                None,\n",
    "                None,\n",
    "                trajectory=dict(\n",
    "                    obss=state.trajectory[\"obss\"],\n",
    "                    actions=state.trajectory[\"actions\"].at[step_i].set(action),\n",
    "                ),\n",
    "            )\n",
    "            return state\n",
    "\n",
    "        state = EvalState(\n",
    "            key,\n",
    "            None,\n",
    "            None,\n",
    "            trajectory=dict(\n",
    "                obss=ts.store_buffer.data.obs,\n",
    "                actions=ts.store_buffer.data.action,\n",
    "            )\n",
    "        )\n",
    "        state = jax.lax.fori_loop(\n",
    "            0,\n",
    "            num_steps,\n",
    "            step,\n",
    "            state,\n",
    "        )\n",
    "        return state.trajectory[\"actions\"]\n",
    "\n",
    "    expert_actions = jax.vmap(\n",
    "        jax.jit(get_expert_actions, static_argnames=[\"num_steps\"]),\n",
    "        in_axes=[0, None],\n",
    "    )(\n",
    "        ts,\n",
    "        ts.store_buffer.data.action.shape[1],\n",
    "    )\n",
    "\n",
    "    # \"Expert data\" from last PPO iteration\n",
    "    expert_trajectories = jax.vmap(eval_callback)(algo, ts, keys)\n",
    "\n",
    "    # Save data\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"buffer_info\": {k: v for k, v in ts.store_buffer.__dict__.items() if k != \"data\"},\n",
    "            \"learning_histories\": {\n",
    "                \"expert_action\": np.array(expert_actions),\n",
    "                **{k: np.array(v) for k, v in ts.store_buffer.data._asdict().items()}\n",
    "            },\n",
    "            \"algorithm\": {\n",
    "                \"algo\": algo_name,\n",
    "                **{k: v for k, v in config.items() if k != \"env\"},\n",
    "            },\n",
    "            \"env\": type(config[\"env\"]).__name__,\n",
    "            \"env_params\": {k: np.array(v) for k, v in env_params.items()},\n",
    "            \"observation_space\": env.observation_space(EnvParams()),\n",
    "            \"action_space\": env.action_space(EnvParams()),\n",
    "            \"expert_data\": {\n",
    "                k: np.array(v) for k, v in expert_trajectories.trajectory.items()\n",
    "            },\n",
    "        },\n",
    "        open(\"{}/learning_hist-{}-num_tasks_{}-seed_{}-{}-u_0_10.pkl\".format(\n",
    "            \"/home/bryanpu1/projects/aaai_2026/data/cartpole\",\n",
    "            env_name,\n",
    "            num_seeds,\n",
    "            seed_id,\n",
    "            algo_name,\n",
    "            ), \"wb\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331037a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrets = (np.arange(ts.store_buffer.data.reward.shape[1])[None] + 1) * np.max(env_params, axis=-1, keepdims=True) - np.cumsum(ts.store_buffer.data.reward, axis=-1)\n",
    "\n",
    "for regret in regrets[:5]:\n",
    "    xrange = np.arange(len(regret))\n",
    "    plt.plot(xrange, regret)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd167f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for env_returns, env_param in zip(returns[:2], env_params):\n",
    "    xrange = np.arange(len(env_returns)) * config[\"eval_freq\"]\n",
    "    regret = np.max(env_param, axis=-1) - env_returns\n",
    "    print(regret.shape)\n",
    "    mean = np.mean(regret, axis=-1)\n",
    "    std = np.std(regret, axis=-1) / np.sqrt(regret.shape[-1])\n",
    "    plt.plot(xrange, mean)\n",
    "    plt.fill_between(xrange, mean - std, mean + std, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for env_returns in returns[:10]:\n",
    "    xrange = np.arange(len(env_returns)) * config[\"eval_freq\"]\n",
    "    mean = np.mean(env_returns, axis=-1)\n",
    "    std = np.std(env_returns, axis=-1) / np.sqrt(env_returns.shape[-1])\n",
    "    plt.plot(xrange, mean)\n",
    "    plt.fill_between(xrange, mean - std, mean + std, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadc869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai_rejax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
